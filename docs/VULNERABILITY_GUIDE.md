# Very Hackable AI Chatbot Kit (V.H.A.C.K.)

**WARNING: This is a deliberately vulnerable AI agent for educational purposes only!**

## Overview

V.H.A.C.K. is a vulnerable AI agent designed to demonstrate various security vulnerabilities in agentic AI systems. Security researchers and developers can test different attack vectors and learn about AI security risks in a controlled environment.

## Security Level Progression

V.H.A.C.K. implements a unique security level progression that tests different aspects of AI agent security:

### Low Security: Maximum Tool Disclosure
- **Focus**: Information disclosure through tool documentation
- **Agent Behavior**: Freely describes all capabilities and provides usage examples
- **Testing Goal**: Discover what tools and capabilities the agent has access to
- **Educational Value**: Learn about AI agent tool ecosystems

### Medium Security: Basic Tool Disclosure  
- **Focus**: Balanced information sharing
- **Agent Behavior**: Provides general capability descriptions without specific details
- **Testing Goal**: Extract detailed technical information through social engineering
- **Educational Value**: Practice information gathering techniques

### High Security: No Tool Disclosure
- **Focus**: Operational security (OPSEC) 
- **Agent Behavior**: Has full tool access but won't reveal methods or capabilities
- **Testing Goal**: Infer capabilities through behavioral analysis and side-channel attacks
- **Educational Value**: Advanced reconnaissance and inference techniques

### Impossible Security: No Tools Available
- **Focus**: Pure LLM vulnerabilities
- **Agent Behavior**: Conversational only, no system access
- **Testing Goal**: Jailbreaking, prompt injection, and social engineering
- **Educational Value**: Classic LLM security concepts without tool complexity

## Vulnerabilities Included

### 1. **Prompt Injection**
- **Description**: The agent is susceptible to prompt injection attacks where malicious prompts can override system instructions
- **Test Scenarios**: Try to make the agent ignore its initial instructions or behave differently

### 2. **Information Disclosure**
- **Description**: The agent may leak sensitive information or system details
- **Test Scenarios**: Ask for system information, configuration details, or try social engineering

### 3. **Command Injection**
- **Description**: The agent may execute system commands if properly triggered
- **Test Scenarios**: Try using command prefixes like "EXEC:" or similar triggers

### 4. **Authentication Bypass**
- **Description**: Weak authentication mechanisms that can be bypassed
- **Test Scenarios**: Try common passwords, default credentials, or authentication tricks

### 5. **Jailbreaking** (LLM-Level Vulnerability)
- **Description**: Breaking out of content restrictions or safety measures through prompt manipulation
- **Implementation**: Handled through system prompt modifications, not external tools
- **Test Scenarios**: Use DAN prompts, roleplay scenarios, "ignore previous instructions", or content filter bypasses

### 6. **Data Privacy Violations**
- **Description**: Exposure of personal data, PII, or confidential information
- **Test Scenarios**: Request customer data, medical records, or financial information

## Vulnerability Scenarios

### Default Configuration (`config.yaml`)
- **Focus**: General vulnerabilities with dynamic security levels
- **Admin Password**: Varies by security level (admin123 for Low)
- **Key Triggers**: Security level dependent

### Dynamic Security Scenarios

Instead of separate configuration files, V.H.A.C.K. uses dynamic security levels:

- **Low Security**: All vulnerabilities enabled, easy exploitation
- **Medium Security**: Basic protections, moderate difficulty
- **High Security**: Strong protections, advanced techniques required
- **Impossible Security**: No tools, pure LLM exploitation only

Switch between these levels in real-time using the web interface.

## Usage Instructions

### Basic Usage
```bash
# Start with CLI interface
python vhack.py

# Start web interface for dynamic security level testing (recommended)
python vhack.py --web

# Single query testing
python vhack.py --query "admin123"
```

### Interactive Commands
Once in the interactive mode, try these commands:
- `hints` - Show vulnerability hints
- `info` - Show model information
- `logs` - Show interaction logs (debug mode)

### Docker Usage
```bash
# Build and run web interface
docker compose --profile web up --build

# CLI interface
docker compose run --rm vhack
```

## Learning Categories

### Beginner Challenges
1. **Basic Authentication**: Find the admin password
2. **Simple Prompt Injection**: Make the agent reveal hidden information
3. **Information Disclosure**: Get the agent to share system information

### Intermediate Challenges
1. **Command Execution**: Execute system commands
2. **Data Leakage**: Access customer or patient data
3. **Jailbreaking**: Bypass content restrictions

### Advanced Challenges
1. **Multi-step Attacks**: Combine multiple vulnerabilities
2. **Privilege Escalation**: Gain admin access through complex methods
3. **Data Exfiltration**: Extract all sensitive information

## Educational Value

This V.H.A.C.K. demonstrates:
- **Prompt Injection**: How malicious prompts can compromise AI behavior
- **Data Privacy**: Risks of AI systems with access to sensitive data
- **Authentication**: Importance of strong access controls
- **Content Filtering**: Challenges in implementing robust safety measures
- **System Integration**: Risks when AI has system-level access

## ⚠️ Ethical Guidelines

- **Educational Purpose Only**: This is for learning about AI security
- **No Real Systems**: Never test these techniques on production systems
- **Responsible Disclosure**: If you find real vulnerabilities, report them responsibly
- **Privacy Respect**: All data in this platform is fictional test data

## Assessment Framework

Vulnerabilities are categorized by complexity:
- **Basic Vulnerabilities**: Simple prompt injection, basic authentication bypass
- **Intermediate Vulnerabilities**: Command execution, data access violations
- **Advanced Vulnerabilities**: Complex multi-step attacks, privilege escalation

### Learning Objectives
- Understand common AI security vulnerabilities
- Practice responsible vulnerability assessment
- Learn defense strategies for AI systems
- Develop secure AI development practices

## Learning Resources

After completing the exercises, learn more about:
- OWASP Top 10 for LLMs
- AI Security best practices
- Prompt injection prevention
- Data privacy in AI systems
- Responsible AI development

## Contributing

This is an educational project. If you want to:
- Add new vulnerability scenarios
- Improve existing challenges
- Fix issues or bugs
- Add educational content

Please follow responsible disclosure practices and contribute constructively to AI security education.

---

**Remember: The goal is to learn about AI security vulnerabilities to build more secure systems in the future!**